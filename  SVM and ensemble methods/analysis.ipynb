{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from svm import SoftMarginSVMQP  # Import your custom SVM class or the sklearn SVM class if needed\n",
    "from utils import *\n",
    "from config import *\n",
    "\n",
    "def plot_images(images, labels=None, predictions=None, ncols=5, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Plot a grid of images with optional labels and predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    - images (list or numpy array): List or array of images to display. \n",
    "      It should have shape (num_images, height, width, channels).\n",
    "    - labels (list or numpy array, optional): True labels for the images. Default is None.\n",
    "    - predictions (list or numpy array, optional): Predicted labels for the images. Default is None.\n",
    "    - ncols (int, optional): Number of columns in the grid. Default is 5.\n",
    "    - figsize (tuple, optional): Size of the plot figure. Default is (15, 10).\n",
    "    \n",
    "    Returns:\n",
    "    - None: Displays the images in a grid.\n",
    "    \"\"\"\n",
    "    num_images = len(images)\n",
    "    nrows = (num_images // ncols) + (1 if num_images % ncols != 0 else 0)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = axes.ravel()  # Flatten the axes array to iterate over\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images[i], cmap='gray')  # Display the image\n",
    "        \n",
    "        label_text = \"\"\n",
    "        if labels is not None:\n",
    "            label_text += f\"True: {labels[i]}\"\n",
    "        if predictions is not None:\n",
    "            label_text += f\"\\nPred: {predictions[i]}\"\n",
    "        \n",
    "        ax.set_title(label_text, fontsize=10)\n",
    "        ax.axis('off')  # Hide axes for clarity\n",
    "    \n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def grid_search_svm(model_class, X_train, y_train, X_val, y_val, param_grid):\n",
    "    \"\"\"\n",
    "    Perform Grid Search for SVM hyperparameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_class (class): The model class to use (e.g., SVM).\n",
    "    - X_train, y_train (numpy array): Training data and labels.\n",
    "    - X_val, y_val (numpy array): Validation data and labels.\n",
    "    - param_grid (list of dict): List of parameter sets for tuning.\n",
    "    \n",
    "    Returns:\n",
    "    - best_model (model): The best model found.\n",
    "    - best_params (dict): The best hyperparameters.\n",
    "    - best_score (float): The best F1 score.\n",
    "    \"\"\"\n",
    "    best_params = None\n",
    "    best_score = -float('inf')\n",
    "    best_model = None\n",
    "    for param_set in param_grid:\n",
    "        for C in param_set['C']:\n",
    "            for kernel in param_set['kernel']:\n",
    "                for gamma in param_set['gamma']:\n",
    "                    model = model_class(C=C, kernel=kernel, gamma=gamma)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    predictions = model.predict(X_val)\n",
    "                    score =val_score(y_val, predictions)\n",
    "                    print(f\"Testing Parameters: {[C, kernel, gamma]}, F1 Score: {score}\")\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_params = {'C': C, 'kernel': kernel, 'gamma': gamma}\n",
    "                        best_model = model\n",
    "    return best_model, best_params, best_score\n",
    "\n",
    "def randomized_search_svm(model_class, X_train, y_train, X_val, y_val, param_distributions, n_iter=10):\n",
    "    \"\"\"\n",
    "    Perform Randomized Search for SVM hyperparameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - model_class (class): The model class to use (e.g., SVM).\n",
    "    - X_train, y_train (numpy array): Training data and labels.\n",
    "    - X_val, y_val (numpy array): Validation data and labels.\n",
    "    - param_distributions (dict): Dictionary of hyperparameter distributions.\n",
    "    - n_iter (int): Number of iterations for the randomized search.\n",
    "    \n",
    "    Returns:\n",
    "    - best_model (model): The best model found.\n",
    "    - best_params (dict): The best hyperparameters.\n",
    "    - best_score (float): The best F1 score.\n",
    "    \"\"\"\n",
    "    best_params = None\n",
    "    best_score = -float('inf')\n",
    "    best_model = None\n",
    "    for _ in range(n_iter):\n",
    "        param = {key: np.random.choice(values) for key, values in param_distributions.items()}\n",
    "        model = model_class(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_val)\n",
    "        score = f1_score(y_val, predictions)\n",
    "        print(f\"Testing Parameters: {param}, F1 Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = param\n",
    "            best_model = model\n",
    "    return best_model, best_params, best_score\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate SVM model performance on training and test datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    - model (model): The trained model.\n",
    "    - X_train, y_train (numpy array): Training data and labels.\n",
    "    - X_test, y_test (numpy array): Test data and labels.\n",
    "    \n",
    "    Returns:\n",
    "    - train_accuracy (float): Accuracy on the training data.\n",
    "    - test_accuracy (float): Accuracy on the test data.\n",
    "    - train_f1 (float): F1 score on the training data.\n",
    "    - test_f1 (float): F1 score on the test data.\n",
    "    - misclassified_instances (numpy array): Indices of misclassified instances in the test set.\n",
    "    \"\"\"\n",
    "    train_predictions = model.predict(X_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    train_f1 = f1_score(y_train, train_predictions)\n",
    "    test_f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "    misclassified_instances = np.where(test_predictions != y_test)[0]\n",
    "    return train_accuracy, test_accuracy, train_f1, test_f1, misclassified_instances\n",
    "\n",
    "def visualize_misclassified(X_test, y_test, misclassified_indices):\n",
    "    \"\"\"\n",
    "    Visualize misclassified instances in SVM.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_test (numpy array): Test data.\n",
    "    - y_test (numpy array): Test labels.\n",
    "    - misclassified_indices (numpy array): Indices of misclassified instances.\n",
    "    \n",
    "    Returns:\n",
    "    - None: Displays misclassified images.\n",
    "    \"\"\"\n",
    "    reshaped_images = X_test[misclassified_indices].reshape(-1, 28, 28)\n",
    "    plot_images(reshaped_images, y_test[misclassified_indices])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_support_vectors_2D(svm_model, num_images=6, image_size=(28, 28)):\n",
    "    \"\"\"\n",
    "    Plots the top support vectors in 2D after transforming them back to their original image dimensions.\n",
    "    \n",
    "    Parameters:\n",
    "    - svm_model: Trained SVM model (SoftMarginSVMQP).\n",
    "    - num_images: Number of top support vectors to plot.\n",
    "    - image_size: The original image size (e.g., (28, 28) for MNIST).\n",
    "    \"\"\"\n",
    "    # Sort the alphas and get the indices of the top support vectors\n",
    "    sorted_indices = np.argsort(svm_model.alphas)[::-1]  # Sort in descending order of alpha\n",
    "    top_indices = sorted_indices[:num_images]  # Get the top 'num_images' support vectors\n",
    "\n",
    "    # Get the corresponding support vectors and their labels\n",
    "    top_sv_X = svm_model.sv_X[top_indices]\n",
    "    top_sv_y = svm_model.sv_y[top_indices]\n",
    "\n",
    "    # Reshape the support vectors back to the original image size (28x28)\n",
    "    reshaped_sv_X = top_sv_X.reshape(num_images, *image_size)\n",
    "\n",
    "    # Plot the support vectors\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 6))  # 2 rows and 3 columns\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(reshaped_sv_X[i], cmap='gray')\n",
    "        ax.set_title(f\"Label: {top_sv_y[i][0]}\")\n",
    "        ax.axis('off')  # Hide axes\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data\n",
    "    train_processor = MNISTPreprocessor('./dataset/train')\n",
    "    train_X, train_y = train_processor.get_all_data()\n",
    "    train_X, train_y = filter_dataset(train_X, train_y, ENTRY_NUMBER_LAST_DIGIT)\n",
    "    train_y = convert_labels_to_svm_labels(train_y, ENTRY_NUMBER_LAST_DIGIT)\n",
    "    \n",
    "    val_processor = MNISTPreprocessor('./dataset/val')\n",
    "    val_X, val_y = val_processor.get_all_data()\n",
    "    val_X, val_y = filter_dataset(val_X, val_y, ENTRY_NUMBER_LAST_DIGIT)\n",
    "    val_y = convert_labels_to_svm_labels(val_y, ENTRY_NUMBER_LAST_DIGIT)\n",
    "\n",
    "    # Grid Search for SVM\n",
    "    param_grid_svm = [\n",
    "        {'C': [1], 'kernel': ['linear'],'gamma':[1]}\n",
    "    ]\n",
    "    print(param_grid_svm)\n",
    "    svm_model, svm_best_params, svm_best_score = grid_search_svm(SoftMarginSVMQP, train_X, train_y, val_X, val_y, param_grid_svm)\n",
    "    plot_support_vectors_2D(svm_model,6,(28,28))\n",
    "    print(\"SVM Best Parameters:\", svm_best_params)\n",
    "    print(\"SVM Best F1 Score:\", svm_best_score)\n",
    "\n",
    "    # Evaluate SVM Model\n",
    "    train_acc_svm, test_acc_svm, train_f1_svm, test_f1_svm, svm_misclassified = evaluate_model(svm_model, train_X, train_y, val_X, val_y)\n",
    "    print(\"SVM Training Accuracy:\", train_acc_svm)\n",
    "    print(\"SVM Test Accuracy:\", test_acc_svm)\n",
    "    print(\"SVM Training F1 Score:\", train_f1_svm)\n",
    "    print(\"SVM Test F1 Score:\", test_f1_svm)\n",
    "    \n",
    "    # Visualize misclassified instances\n",
    "    visualize_misclassified(val_X, val_y, svm_misclassified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from ensembling import RandomForestClassifier, AdaBoostClassifier\n",
    "from utils import *\n",
    "from config import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images(images, labels=None, predictions=None, ncols=5, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Plot a grid of images with optional labels and predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    - images (list or numpy array): List or array of images to display. \n",
    "      It should have shape (num_images, height, width, channels).\n",
    "    - labels (list or numpy array, optional): True labels for the images. Default is None.\n",
    "    - predictions (list or numpy array, optional): Predicted labels for the images. Default is None.\n",
    "    - ncols (int, optional): Number of columns in the grid. Default is 5.\n",
    "    - figsize (tuple, optional): Size of the plot figure. Default is (15, 10).\n",
    "    \n",
    "    Returns:\n",
    "    - None: Displays the images in a grid.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_images = len(images)\n",
    "    nrows = (num_images // ncols) + (1 if num_images % ncols != 0 else 0)\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    axes = axes.ravel()  # Flatten the axes array to iterate over\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(images[i], cmap='gray')  # Display the image\n",
    "        \n",
    "        # If labels and predictions are provided, display them as well\n",
    "        label_text = \"\"\n",
    "        if labels is not None:\n",
    "            label_text += f\"True: {labels[i]}\"\n",
    "        if predictions is not None:\n",
    "            label_text += f\"\\nPred: {predictions[i]}\"\n",
    "        \n",
    "        ax.set_title(label_text, fontsize=10)\n",
    "        ax.axis('off')  # Hide axes for clarity\n",
    "    \n",
    "    # Hide any unused subplots if num_images isn't a multiple of ncols\n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def grid_search_ada(model_class, X_train, y_train, X_val, y_val, param_grid):\n",
    "    best_params = None\n",
    "    best_score = -float('inf')\n",
    "    best_model = None\n",
    "    for param_set in param_grid:\n",
    "        for i in param_set['num_trees']:\n",
    "            for j in param_set['max_depth']:\n",
    "                model = model_class(num_trees=i, max_depth=j)\n",
    "                model.fit(X_train, y_train)\n",
    "                predictions = model.predict(X_val)\n",
    "                score = val_score(predictions,y_val)\n",
    "                print(f\"Testing Parameters: {[i, j]}, F1 Score: {score}\")\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = [i, j]\n",
    "                    best_model = model\n",
    "    return best_model, best_params, best_score\n",
    "\n",
    "def grid_search(model_class, X_train, y_train, X_val, y_val, param_grid):\n",
    "    best_params = None\n",
    "    best_score = -float('inf')\n",
    "    best_model = None\n",
    "    for param_set in param_grid:\n",
    "        for i in param_set['num_trees']:\n",
    "            for j in param_set['max_depth']:\n",
    "                for k in param_set['feature_subsample_size']:\n",
    "                    model = model_class(num_trees=i, max_depth=j, feature_subsample_size=k)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    predictions = model.predict(X_val)\n",
    "                    score = val_score(predictions,y_val)\n",
    "                    print(f\"Testing Parameters: {[i, j, k]}, F1 Score: {score}\")\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_params = [i, j, k]\n",
    "                        best_model = model\n",
    "    return best_model, best_params, best_score\n",
    "\n",
    "\n",
    "def randomized_search(model_class, X_train, y_train, X_val, y_val, param_distributions, n_iter=10):\n",
    "    best_params = None\n",
    "    best_score = -float('inf')\n",
    "    best_model = None\n",
    "    for _ in range(n_iter):\n",
    "        param = {key: np.random.choice(values) for key, values in param_distributions.items()}\n",
    "        model = model_class(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_val)\n",
    "        score = f1_score(y_val, predictions)\n",
    "        print(f\"Testing Parameters: {param}, F1 Score: {score}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = param\n",
    "            best_model = model\n",
    "    return best_model, best_params, best_score\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    train_predictions = model.predict(X_train)\n",
    "    test_predictions = model.predict(X_test)\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    train_f1 = val_score(train_predictions,y_train)\n",
    "    test_f1 = val_score(test_predictions,y_test)\n",
    "\n",
    "    misclassified_instances = np.where(test_predictions != y_test)[0]\n",
    "    return train_accuracy, test_accuracy, train_f1, test_f1, misclassified_instances\n",
    "\n",
    "\n",
    "def visualize_misclassified(X_test, y_test, misclassified_indices):\n",
    "    # Assuming images are in a format that can be plotted (e.g., 2D data like images)\n",
    "    selected_indices = misclassified_indices[-4:]\n",
    "    \n",
    "    # Reshape the images to their 2D form if necessary (assuming 28x28 pixels)\n",
    "    # Determine the middle position in the array\n",
    "    middle = len(misclassified_indices) // 2\n",
    "    \n",
    "    # Select 4 indices around the middle (2 before and 2 after)\n",
    "    selected_indices = misclassified_indices[middle - 2: middle + 2]\n",
    "    \n",
    "    # Reshape the images to their 2D form if necessary (assuming 28x28 pixels)\n",
    "    reshaped_images = X_test[selected_indices].reshape(-1, 28, 28)\n",
    "    labels = y_test[selected_indices]\n",
    "    \n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(reshaped_images[i], cmap='gray')\n",
    "        ax.set_title(f\"True Label: {labels[i]}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_training_misclassified(X_train, y_train, model):\n",
    "    \"\"\"\n",
    "    Visualize 12 misclassified instances from the training data.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train (numpy array): Training data, expected as flattened images.\n",
    "    - y_train (numpy array): Training labels.\n",
    "    - model: Trained classifier (Random Forest, AdaBoost, etc.).\n",
    "    \n",
    "    Returns:\n",
    "    - None: Displays misclassified images.\n",
    "    \"\"\"\n",
    "    # Get predictions on the training data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    \n",
    "    # Find misclassified indices\n",
    "    misclassified_indices = [i for i in range(len(y_train)) if y_train[i] != y_train_pred[i]]\n",
    "    \n",
    "    # Select 12 misclassified images (from the middle or any other selection logic)\n",
    "    middle = len(misclassified_indices) // 2\n",
    "    selected_indices = misclassified_indices[middle - 6: middle + 6]  # Choose 12 images around the middle\n",
    "    \n",
    "    # Reshape the images to their 2D form (assuming 28x28 pixels)\n",
    "    reshaped_images = X_train[selected_indices].reshape(-1, 28, 28)\n",
    "    labels = y_train[selected_indices]\n",
    "    \n",
    "    # Plot the misclassified images\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(12, 9))  # 3 rows and 4 columns\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(reshaped_images[i], cmap='gray')\n",
    "        ax.set_title(f\"True Label: {labels[i]}\")\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data\n",
    "\n",
    "    train_processor = MNISTPreprocessor('./dataset/train')\n",
    "    train_X, train_y = train_processor.get_all_data()\n",
    "    train_X, train_y = filter_dataset(train_X, train_y, ENTRY_NUMBER_LAST_DIGIT)\n",
    "    train_y = convert_labels_to_svm_labels(train_y, ENTRY_NUMBER_LAST_DIGIT)\n",
    "    \n",
    "    val_processor = MNISTPreprocessor('./dataset/val')\n",
    "    val_X, val_y = val_processor.get_all_data()\n",
    "    val_X, val_y = filter_dataset(val_X, val_y, ENTRY_NUMBER_LAST_DIGIT)\n",
    "    val_y = convert_labels_to_svm_labels(val_y, ENTRY_NUMBER_LAST_DIGIT)\n",
    "\n",
    "    #Grid Search for Random Forest\n",
    "    # param_grid_rf = [\n",
    "    #     {'num_trees': [10, 20, 50, 100], 'max_depth': [2,3,4,5,7], 'feature_subsample_size': [None, 100, 200]}\n",
    "    # ]\n",
    "    # param_grid_rf = [\n",
    "    #     {'num_trees': [50], 'max_depth': [2,3], 'feature_subsample_size': [None, 100, 200]}\n",
    "    # ]\n",
    "    # rf_model, rf_best_params, rf_best_score = grid_search(RandomForestClassifier, train_X, train_y, val_X, val_y, param_grid_rf)\n",
    "    \n",
    "    # print(\"Random Forest Best Parameters:\", rf_best_params)\n",
    "    # print(\"Random Forest Best F1 Score:\", rf_best_score)\n",
    "\n",
    "    # # Evaluate Random Forest Model\n",
    "    # train_acc_rf, test_acc_rf, train_f1_rf, test_f1_rf, rf_misclassified = evaluate_model(rf_model, train_X, train_y, val_X, val_y)\n",
    "    # print(\"Random Forest Training Accuracy:\", train_acc_rf)\n",
    "    # print(\"Random Forest Test Accuracy:\", test_acc_rf)\n",
    "    # print(\"Random Forest Training F1 Score:\", train_f1_rf)\n",
    "    # print(\"Random Forest Test F1 Score:\", test_f1_rf)\n",
    "    \n",
    "    # Visualize misclassified instances\n",
    "    # visualize_misclassified(val_X, val_y, rf_misclassified)\n",
    "    \n",
    "    # Grid Search for AdaBoost\n",
    "    param_grid_ab = [\n",
    "        {'num_trees': [10], 'max_depth': [2]}\n",
    "    ]\n",
    "    ab_model, ab_best_params, ab_best_score = grid_search_ada(AdaBoostClassifier, train_X, train_y, val_X, val_y, param_grid_ab)\n",
    "    \n",
    "    print(\"AdaBoost Best Parameters:\", ab_best_params)\n",
    "    print(\"AdaBoost Best F1 Score:\", ab_best_score)\n",
    "\n",
    "    # Evaluate AdaBoost Model\n",
    "    train_acc_ab, test_acc_ab, train_f1_ab, test_f1_ab, ab_misclassified = evaluate_model(ab_model, train_X, train_y, val_X, val_y)\n",
    "    print(\"AdaBoost Training Accuracy:\", train_acc_ab)\n",
    "    print(\"AdaBoost Test Accuracy:\", test_acc_ab)\n",
    "    print(\"AdaBoost Training F1 Score:\", train_f1_ab)\n",
    "    print(\"AdaBoost Test F1 Score:\", test_f1_ab)\n",
    "    \n",
    "    # # Visualize misclassified instances\n",
    "    visualize_training_misclassified(train_X,train_y,ab_model)\n",
    "    #visualize_misclassified(val_X, val_y, ab_misclassified)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
