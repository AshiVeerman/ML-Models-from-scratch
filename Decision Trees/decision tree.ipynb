{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['management' 'technician' 'entrepreneur' 'blue-collar' 'unknown'\n",
      " 'retired' 'admin.' 'services' 'self-employed' 'unemployed' 'housemaid'\n",
      " 'student']\n",
      "['married' 'single' 'divorced']\n",
      "['yes' 'no']\n",
      "['no' 'yes']\n",
      "['unknown' 'cellular' 'telephone']\n",
      "['may' 'jun' 'jul' 'aug' 'oct' 'nov' 'dec' 'jan' 'feb' 'mar' 'apr' 'sep']\n",
      "['unknown' 'failure' 'other' 'success']\n",
      "['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "print(df['job'].unique())\n",
    "print(df['marital'].unique())\n",
    "print(df['housing'].unique())\n",
    "print(df['loan'].unique())\n",
    "print(df['contact'].unique())\n",
    "print(df['month'].unique())\n",
    "print(df['poutcome'].unique())\n",
    "print(df['default'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job\n",
      "blue-collar      9732\n",
      "management       9458\n",
      "technician       7597\n",
      "admin.           5171\n",
      "services         4154\n",
      "retired          2264\n",
      "self-employed    1579\n",
      "entrepreneur     1487\n",
      "unemployed       1303\n",
      "housemaid        1240\n",
      "student           938\n",
      "unknown           288\n",
      "Name: count, dtype: int64\n",
      "marital\n",
      "married     27214\n",
      "single      12790\n",
      "divorced     5207\n",
      "Name: count, dtype: int64\n",
      "housing\n",
      "yes    25130\n",
      "no     20081\n",
      "Name: count, dtype: int64\n",
      "loan\n",
      "no     37967\n",
      "yes     7244\n",
      "Name: count, dtype: int64\n",
      "contact\n",
      "cellular     29285\n",
      "unknown      13020\n",
      "telephone     2906\n",
      "Name: count, dtype: int64\n",
      "month\n",
      "may    13766\n",
      "jul     6895\n",
      "aug     6247\n",
      "jun     5341\n",
      "nov     3970\n",
      "apr     2932\n",
      "feb     2649\n",
      "jan     1403\n",
      "oct      738\n",
      "sep      579\n",
      "mar      477\n",
      "dec      214\n",
      "Name: count, dtype: int64\n",
      "poutcome\n",
      "unknown    36959\n",
      "failure     4901\n",
      "other       1840\n",
      "success     1511\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['job'].value_counts())\n",
    "print(df['marital'].value_counts())\n",
    "print(df['housing'].value_counts())\n",
    "print(df['loan'].value_counts())\n",
    "print(df['contact'].value_counts())\n",
    "print(df['month'].value_counts())\n",
    "print(df['poutcome'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  default  balance  housing  loan  day  duration  campaign  pdays  \\\n",
      "0   58        0     2143        1     0    5       261         1     -1   \n",
      "1   44        0       29        1     0    5       151         1     -1   \n",
      "2   33        0        2        1     1    5        76         1     -1   \n",
      "3   47        0     1506        1     0    5        92         1     -1   \n",
      "4   33        0        1        0     0    5       198         1     -1   \n",
      "\n",
      "   previous  ...  month_mar  month_may  month_nov  month_oct  month_sep  \\\n",
      "0         0  ...      False       True      False      False      False   \n",
      "1         0  ...      False       True      False      False      False   \n",
      "2         0  ...      False       True      False      False      False   \n",
      "3         0  ...      False       True      False      False      False   \n",
      "4         0  ...      False       True      False      False      False   \n",
      "\n",
      "   poutcome_failure  poutcome_other  poutcome_success  poutcome_unknown  y  \n",
      "0             False           False             False              True  0  \n",
      "1             False           False             False              True  0  \n",
      "2             False           False             False              True  0  \n",
      "3             False           False             False              True  0  \n",
      "4             False           False             False              True  0  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/yhnwltxs6t7_4m8hs0lg4_2m0000gn/T/ipykernel_875/2895074780.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  one_hot_encoded_data['loan'] = one_hot_encoded_data['loan'].replace({'yes': 1, 'no': 0})\n",
      "/var/folders/y8/yhnwltxs6t7_4m8hs0lg4_2m0000gn/T/ipykernel_875/2895074780.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  one_hot_encoded_data['housing'] = one_hot_encoded_data['housing'].replace({'yes': 1, 'no': 0})\n",
      "/var/folders/y8/yhnwltxs6t7_4m8hs0lg4_2m0000gn/T/ipykernel_875/2895074780.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  one_hot_encoded_data['default'] = one_hot_encoded_data['default'].replace({'yes': 1, 'no': 0})\n",
      "/var/folders/y8/yhnwltxs6t7_4m8hs0lg4_2m0000gn/T/ipykernel_875/2895074780.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  one_hot_encoded_data['y'] = one_hot_encoded_data['y'].replace({'yes': 1, 'no': 0})\n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded_data = pd.get_dummies(df.iloc[:,:-1], columns = ['job','education','marital','contact','month','poutcome'])\n",
    "one_hot_encoded_data['loan'] = one_hot_encoded_data['loan'].replace({'yes': 1, 'no': 0})\n",
    "one_hot_encoded_data['housing'] = one_hot_encoded_data['housing'].replace({'yes': 1, 'no': 0})\n",
    "one_hot_encoded_data['default'] = one_hot_encoded_data['default'].replace({'yes': 1, 'no': 0})\n",
    "one_hot_encoded_data['y']=df.iloc[:,-1]\n",
    "one_hot_encoded_data['y'] = one_hot_encoded_data['y'].replace({'yes': 1, 'no': 0})\n",
    "print(one_hot_encoded_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "1    39922\n",
      "0    39922\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "df = pd.DataFrame(one_hot_encoded_data)\n",
    "df_majority = df[df['y'] == 0]\n",
    "df_minority = df[df['y'] == 1]\n",
    "df_minority_upsampled = resample(df_minority, replace=True,n_samples=len(df_majority),random_state=42)\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "df_upsampled = df_upsampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "one_hot_encoded_data = df_upsampled\n",
    "print(df_upsampled['y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Decision Tree Implementation\n",
    "from collections import Counter\n",
    "class Node():\n",
    "    def __init__(self,feature=None, threshold=None, left=None, right=None, gain=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.gain = gain\n",
    "        self.value = value\n",
    "\n",
    "class Decision_Tree():\n",
    "    def __init__(self, min_samples=25, max_depth=2, alpha=0.0):\n",
    "        self.min_samples = min_samples\n",
    "        self.max_depth = max_depth\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def split_data(self, X, feature, threshold):\n",
    "        left_indices = np.where(X[:, feature] <= threshold)[0]\n",
    "        right_indices = np.where(X[:, feature] > threshold)[0]\n",
    "        return left_indices, right_indices\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        unique_vals, counts = np.unique(y, return_counts=True)\n",
    "        probs = counts / len(y)\n",
    "        entropy = -np.sum(probs * np.log2(probs + 1e-9)) \n",
    "        return entropy\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        unique_vals, counts = np.unique(y, return_counts=True)\n",
    "        probs = counts / len(y)\n",
    "        gini = 1 - np.sum(probs ** 2)\n",
    "        return gini\n",
    "    \n",
    "    def info_gain(self, parent, left, right, metric):\n",
    "        info_gain=0\n",
    "        if len(left) == 0 or len(right) == 0:\n",
    "            return 0\n",
    "        if (metric==\"entropy\"):\n",
    "            parent_en = self.entropy(parent)\n",
    "            weight_left = len(left)/len(parent)\n",
    "            weigth_right = len(right)/len(parent)\n",
    "            left_en = self.entropy(left)\n",
    "            right_en = self.entropy(right)\n",
    "            info_gain = parent_en - (weight_left*left_en + weigth_right*right_en)\n",
    "        else:\n",
    "            parent_gn = self.gini_index(parent)\n",
    "            weight_left = len(left)/len(parent)\n",
    "            weigth_right = len(right)/len(parent)\n",
    "            left_gn = self.gini_index(left)\n",
    "            right_gn = self.gini_index(right)\n",
    "            info_gain = parent_gn - (weight_left*left_gn + weigth_right*right_gn)\n",
    "        return info_gain\n",
    "    \n",
    "    def best_split(self, X,y, num_samples, num_features):\n",
    "        best_split = {'gain':-1, 'feature':None, 'threshold':None}\n",
    "        for feature_idx in range(num_features):\n",
    "            thresholds = np.unique(X[:,feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                left_idx,right_idx= self.split_data(X, feature_idx, threshold)\n",
    "                if (len(left_idx)>0 and len(right_idx)>0):\n",
    "                    left_y = y[left_idx]\n",
    "                    right_y = y[right_idx]\n",
    "                    info_gain = self.info_gain(y,left_y,right_y,\"entropy\")\n",
    "                    #print(info_gain)\n",
    "                    if (info_gain > best_split['gain']):\n",
    "                        best_split['feature']=feature_idx\n",
    "                        best_split['threshold']=threshold\n",
    "                        best_split['gain']=info_gain\n",
    "                        best_split['left_idx']=left_idx\n",
    "                        best_split['right_idx']=right_idx\n",
    "        return best_split\n",
    "    \n",
    "    def leaf_value(self,y):\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "\n",
    "    def build_tree(self, X, y, curr_depth=0):\n",
    "        if (self.max_depth is not None and curr_depth >= self.max_depth) or (X.shape[0] < self.min_samples) or len(set(y)) == 1:\n",
    "            leaf_val=self.leaf_value(y)\n",
    "            return Node(value=leaf_val)\n",
    "        n_samples , n_features = X.shape\n",
    "        best_split = self.best_split(X,y, n_samples, n_features)\n",
    "        if best_split['feature'] is None:\n",
    "            leaf_val=self.leaf_value(y)\n",
    "            return Node(value=leaf_val)\n",
    "        \n",
    "        if not np.any(best_split['left_idx']) or not np.any(best_split['right_idx']):\n",
    "            leaf_val=self.leaf_value(y)\n",
    "            return Node(value=leaf_val)\n",
    "\n",
    "        left_node = self.build_tree(X[best_split['left_idx']], y[best_split['left_idx']], curr_depth + 1)  \n",
    "        right_node = self.build_tree(X[best_split['right_idx']], y[best_split['right_idx']], curr_depth + 1)\n",
    "\n",
    "        return Node(best_split['feature'],best_split['threshold'],left_node,right_node,best_split['gain'])\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build_tree(X,y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            pred = self.make_pred(x,self.root)\n",
    "            predictions.append(pred)\n",
    "        predictions = np.array(predictions)\n",
    "        return predictions\n",
    "    \n",
    "    def make_pred(self, x, node):\n",
    "        if node.value!=None:\n",
    "            return node.value\n",
    "        else:\n",
    "            feature=x[node.feature]\n",
    "            if (feature<=node.threshold):\n",
    "                return self.make_pred(x, node.left)\n",
    "            else:\n",
    "                return self.make_pred(x, node.right)\n",
    "    \n",
    "    def count_nodes(self, node=None):\n",
    "        if node is None:\n",
    "            node = self.root \n",
    "        if node.value is not None: \n",
    "            return 1\n",
    "        left_count = self.count_nodes(node.left) if node.left is not None else 0\n",
    "        right_count = self.count_nodes(node.right) if node.right is not None else 0\n",
    "        return 1 + left_count + right_count  \n",
    "    \n",
    "    def prune_tree(self, X_val, y_val, node=None):\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        if node.value is not None:\n",
    "            return node\n",
    "\n",
    "        left_mask = X_val[:, node.feature] <= node.threshold\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        if node.left is not None:\n",
    "            node.left = self.prune_tree(X_val[left_mask], y_val[left_mask],node.left)\n",
    "        if node.right is not None:\n",
    "            node.right = self.prune_tree(X_val[right_mask], y_val[right_mask],node.right)\n",
    "\n",
    "        before_prune_error = self.calculate_error(y_val, self.predict(X_val))\n",
    "\n",
    "        node_value = self.leaf_value(y_val)\n",
    "        pruned_error = self.calculate_error(y_val, np.full_like(y_val, node_value))\n",
    "\n",
    "        if pruned_error + self.alpha <= before_prune_error:\n",
    "            node.left = None\n",
    "            node.right = None\n",
    "            node.value = node_value\n",
    "\n",
    "        return node\n",
    "\n",
    "    def calculate_error(self, y_true, y_pred):\n",
    "        return np.sum(y_true != y_pred) / len(y_true)\n",
    "    \n",
    "\n",
    "    def precision(self, y_true, y_pred):\n",
    "        true_positive = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        false_positive = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        \n",
    "        precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) != 0 else 0\n",
    "        return precision\n",
    "\n",
    "    def recall(self, y_true, y_pred):\n",
    "        true_positive = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        false_negative = np.sum((y_true == 1) & (y_pred == 0))\n",
    "        recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) != 0 else 0\n",
    "        return recall\n",
    "\n",
    "    def f1_score(self, y_true, y_pred):\n",
    "        precision = self.precision(y_true, y_pred)\n",
    "        recall = self.recall(y_true, y_pred)\n",
    "        \n",
    "        if precision + recall == 0:\n",
    "            return 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "\n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "        precision = self.precision(y_true, y_pred)\n",
    "        recall = self.recall(y_true, y_pred)\n",
    "        f1 = self.f1_score(y_true, y_pred)\n",
    "        \n",
    "        return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, random_state=42, test_size=0.2):\n",
    "    n_samples = X.shape[0]\n",
    "    np.random.seed(random_state)\n",
    "    shuffled_indices = np.random.permutation(np.arange(n_samples))\n",
    "    test_size = int(n_samples * test_size)\n",
    "    test_indices = shuffled_indices[:test_size]\n",
    "    train_indices = shuffled_indices[test_size:]\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(one_hot_encoded_data.iloc[:,:-1]), np.array(one_hot_encoded_data.iloc[:,-1]), random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 25\n",
      "Model's Train Accuracy: 0.8896845364815174\n",
      "Model's Test Accuracy: 0.887082503870825\n",
      "\n",
      "2 50\n",
      "Model's Train Accuracy: 0.8896845364815174\n",
      "Model's Test Accuracy: 0.887082503870825\n",
      "\n",
      "2 100\n",
      "Model's Train Accuracy: 0.8896845364815174\n",
      "Model's Test Accuracy: 0.887082503870825\n",
      "\n",
      "2 125\n",
      "Model's Train Accuracy: 0.8896845364815174\n",
      "Model's Test Accuracy: 0.887082503870825\n",
      "\n",
      "5 25\n",
      "Model's Train Accuracy: 0.9039785451629849\n",
      "Model's Test Accuracy: 0.8948241539482416\n",
      "\n",
      "5 50\n",
      "Model's Train Accuracy: 0.9036744173186984\n",
      "Model's Test Accuracy: 0.8946029639460297\n",
      "\n",
      "5 100\n",
      "Model's Train Accuracy: 0.9036467693328541\n",
      "Model's Test Accuracy: 0.8951559389515594\n",
      "\n",
      "5 125\n",
      "Model's Train Accuracy: 0.9036467693328541\n",
      "Model's Test Accuracy: 0.8951559389515594\n",
      "\n",
      "10 25\n",
      "Model's Train Accuracy: 0.9158671790760043\n",
      "Model's Test Accuracy: 0.893607608936076\n",
      "\n",
      "10 50\n",
      "Model's Train Accuracy: 0.9124111808454755\n",
      "Model's Test Accuracy: 0.8944923689449237\n",
      "\n",
      "10 100\n",
      "Model's Train Accuracy: 0.9105587657939119\n",
      "Model's Test Accuracy: 0.8957089139570892\n",
      "\n",
      "10 125\n",
      "Model's Train Accuracy: 0.9097569742044292\n",
      "Model's Test Accuracy: 0.8957089139570892\n",
      "\n",
      "12 25\n",
      "Model's Train Accuracy: 0.9235533191407006\n",
      "Model's Test Accuracy: 0.8964830789648308\n",
      "\n",
      "12 50\n",
      "Model's Train Accuracy: 0.9177748900992563\n",
      "Model's Test Accuracy: 0.8972572439725724\n",
      "\n",
      "12 100\n",
      "Model's Train Accuracy: 0.9141253559678177\n",
      "Model's Test Accuracy: 0.8978102189781022\n",
      "\n",
      "12 125\n",
      "Model's Train Accuracy: 0.9126876607039177\n",
      "Model's Test Accuracy: 0.8980314089803141\n",
      "\n",
      "15 25\n",
      "Model's Train Accuracy: 0.9320412507948795\n",
      "Model's Test Accuracy: 0.8959301039593011\n",
      "\n",
      "15 50\n",
      "Model's Train Accuracy: 0.9226685835936852\n",
      "Model's Test Accuracy: 0.8986949789869498\n",
      "\n",
      "15 100\n",
      "Model's Train Accuracy: 0.9171942823965274\n",
      "Model's Test Accuracy: 0.8990267639902676\n",
      "\n",
      "15 125\n",
      "Model's Train Accuracy: 0.9155354032458736\n",
      "Model's Test Accuracy: 0.8993585489935855\n",
      "\n",
      "20 25\n",
      "Model's Train Accuracy: 0.9405015344632144\n",
      "Model's Test Accuracy: 0.8910639239106393\n",
      "\n",
      "20 50\n",
      "Model's Train Accuracy: 0.9268434294561642\n",
      "Model's Test Accuracy: 0.8948241539482416\n",
      "\n",
      "20 100\n",
      "Model's Train Accuracy: 0.9195720091791313\n",
      "Model's Test Accuracy: 0.896040698960407\n",
      "\n",
      "20 125\n",
      "Model's Train Accuracy: 0.9173601703115928\n",
      "Model's Test Accuracy: 0.8965936739659367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning\n",
    "max_depth = [2,5,10,12,15,20]\n",
    "min_samples = [25, 50, 100, 125]\n",
    "for i in max_depth:\n",
    "    for j in min_samples:\n",
    "        model = Decision_Tree(min_samples=j,max_depth=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict(X_train)\n",
    "        print(i,j)\n",
    "        print(f\"Model's Train Accuracy: {accuracy(y_train, pred)}\")\n",
    "        predictions = model.predict(X_test)\n",
    "        print(f\"Model's Test Accuracy: {accuracy(y_test, predictions)}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model and calculating Metrics for training and testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8719550378859039\n",
      "Precision: 0.8537543525490313\n",
      "Recall: 0.8978154732098147\n",
      "F1-Score: 0.8752307293335164\n",
      "Accuracy: 0.8623496993987976\n",
      "Precision: 0.8429182509505704\n",
      "Recall: 0.8900878293601003\n",
      "F1-Score: 0.8658611009398267\n"
     ]
    }
   ],
   "source": [
    "# Fit your model\n",
    "tree = Decision_Tree(min_samples=25, max_depth=10)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = tree.predict(X_train)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1 = tree.calculate_metrics(y_train, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1 = tree.calculate_metrics(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes in the tree: 705\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes in the tree\n",
    "node_count = tree.count_nodes()\n",
    "print(f\"Total number of nodes in the tree: {node_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Node at 0x16dee2460>"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.prune_tree(X_val=X_test,y_val=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating Metrics for training and testing data after pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8685108648005511\n",
      "Precision: 0.8482626053526542\n",
      "Recall: 0.8977215823735604\n",
      "F1-Score: 0.8722915748019524\n",
      "Accuracy: 0.8635395791583166\n",
      "Precision: 0.8425411096652076\n",
      "Recall: 0.8936010037641154\n",
      "F1-Score: 0.8673202216403825\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree.predict(X_train)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1 = tree.calculate_metrics(y_train, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1 = tree.calculate_metrics(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes in the tree: 385\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes in the tree\n",
    "node_count = tree.count_nodes()\n",
    "print(f\"Total number of nodes in the tree: {node_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating results on test.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/yhnwltxs6t7_4m8hs0lg4_2m0000gn/T/ipykernel_875/823888466.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  one_hot_encoded_data['loan'] = one_hot_encoded_data['loan'].replace({'yes': 1, 'no': 0})\n",
      "/var/folders/y8/yhnwltxs6t7_4m8hs0lg4_2m0000gn/T/ipykernel_875/823888466.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  one_hot_encoded_data['housing'] = one_hot_encoded_data['housing'].replace({'yes': 1, 'no': 0})\n",
      "/var/folders/y8/yhnwltxs6t7_4m8hs0lg4_2m0000gn/T/ipykernel_875/823888466.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  one_hot_encoded_data['default'] = one_hot_encoded_data['default'].replace({'yes': 1, 'no': 0})\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/Test.csv')\n",
    "one_hot_encoded_data = pd.get_dummies(df.iloc[:,:-1], columns = ['job','education','marital','contact','month','poutcome'])\n",
    "one_hot_encoded_data['loan'] = one_hot_encoded_data['loan'].replace({'yes': 1, 'no': 0})\n",
    "one_hot_encoded_data['housing'] = one_hot_encoded_data['housing'].replace({'yes': 1, 'no': 0})\n",
    "one_hot_encoded_data['default'] = one_hot_encoded_data['default'].replace({'yes': 1, 'no': 0})\n",
    "y_pred = tree.predict(np.array(one_hot_encoded_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_pred)\n",
    "df.to_csv('output.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
